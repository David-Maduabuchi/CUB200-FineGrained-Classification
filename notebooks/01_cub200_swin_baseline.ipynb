{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROTOTYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Minimal installs: only what we need\n",
    "!pip install -q timm==0.9.12 sentence-transformers==2.7.0 wandb==0.17.0 torchmetrics==1.4.0.post0\n",
    "\n",
    "# Import essentials\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "from torch import nn\n",
    "import wandb\n",
    "# Environment tweaks\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Seeds for reproducibility (enough for CUB)\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = False  # Deterministic\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Logging: only to file + console, no spam\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    force=True,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler(), logging.FileHandler(\"/kaggle/working/train.log\", mode=\"w\")]\n",
    ")\n",
    "\n",
    "# Device check\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"PyTorch {torch.__version__} | Device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    logging.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    logging.info(f\"Initial VRAM: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "else:\n",
    "    logging.warning(\"No GPU detected. Training will be slow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Dataset Definition (Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================== FINAL DATASET & SPLIT CELL (VISION-ONLY) ======================\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "SEED = 42\n",
    "NUM_CLASSES = 200\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 48\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# ---------------- PATHS ----------------\n",
    "DATA_ROOT = \"/kaggle/input/cub2002011/CUB_200_2011\"\n",
    "IMAGES_DIR = os.path.join(DATA_ROOT, \"images\")\n",
    "IMAGES_FILE = os.path.join(DATA_ROOT, \"images.txt\")\n",
    "LABELS_FILE = os.path.join(DATA_ROOT, \"image_class_labels.txt\")\n",
    "BB_FILE = os.path.join(DATA_ROOT, \"bounding_boxes.txt\")\n",
    "SPLIT_FILE = os.path.join(DATA_ROOT, \"train_test_split.txt\")\n",
    "\n",
    "# ---------------- LOAD METADATA ----------------\n",
    "images_df = pd.read_csv(IMAGES_FILE, sep=\" \", header=None, names=[\"img_id\", \"path\"])\n",
    "labels_df = pd.read_csv(LABELS_FILE, sep=\" \", header=None, names=[\"img_id\", \"class_id\"])\n",
    "bb_df = pd.read_csv(BB_FILE, sep=\" \", header=None, names=[\"img_id\", \"x\", \"y\", \"width\", \"height\"])\n",
    "split_df = pd.read_csv(SPLIT_FILE, sep=\" \", header=None, names=[\"img_id\", \"is_train\"])\n",
    "\n",
    "img_paths = dict(zip(images_df.img_id, images_df.path))\n",
    "labels = {row.img_id: row.class_id - 1 for row in labels_df.itertuples()}  # 0–199\n",
    "bboxes = {row.img_id: (row.x, row.y, row.width, row.height) for row in bb_df.itertuples()}\n",
    "\n",
    "train_ids = split_df[split_df[\"is_train\"] == 1][\"img_id\"].tolist()\n",
    "test_ids  = split_df[split_df[\"is_train\"] == 0][\"img_id\"].tolist()\n",
    "\n",
    "print(f\"Official train samples: {len(train_ids)}\")\n",
    "print(f\"Official test samples:  {len(test_ids)}\")\n",
    "\n",
    "# ---------------- DATASET ----------------\n",
    "class CUBVisionDataset(Dataset):\n",
    "    def __init__(self, image_ids, train=False):\n",
    "        self.ids = list(image_ids)\n",
    "        self.train = train\n",
    "\n",
    "        self.base_tf = T.Compose([\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(IMG_SIZE),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        self.aug_tf = T.Compose([\n",
    "            T.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0)),\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "            T.RandomRotation(15),\n",
    "        ])\n",
    "\n",
    "    def crop_bbox(self, img, bbox):\n",
    "        x, y, w, h = map(int, bbox)\n",
    "        m = 0.15\n",
    "        x = max(0, int(x - w * m))\n",
    "        y = max(0, int(y - h * m))\n",
    "        w = int(w * (1 + 2 * m))\n",
    "        h = int(h * (1 + 2 * m))\n",
    "        return img.crop((x, y, x + w, y + h))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.ids[idx]\n",
    "\n",
    "        path = os.path.join(IMAGES_DIR, img_paths[img_id])\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = self.crop_bbox(img, bboxes[img_id])\n",
    "\n",
    "        if self.train:\n",
    "            img = self.aug_tf(img)\n",
    "        img = self.base_tf(img)\n",
    "\n",
    "        label = labels[img_id]\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# ---------------- DATASETS ----------------\n",
    "full_train_dataset = CUBVisionDataset(train_ids, train=True)\n",
    "full_val_dataset   = CUBVisionDataset(train_ids, train=False)\n",
    "test_dataset       = CUBVisionDataset(test_ids,  train=False)\n",
    "\n",
    "# ---------------- STRATIFIED VAL SPLIT ----------------\n",
    "val_size_per_class = 3\n",
    "\n",
    "class_to_indices = {}\n",
    "for idx, img_id in enumerate(train_ids):\n",
    "    class_to_indices.setdefault(labels[img_id], []).append(idx)\n",
    "\n",
    "train_indices, val_indices = [], []\n",
    "for cls, indices in class_to_indices.items():\n",
    "    random.shuffle(indices)\n",
    "    val_indices.extend(indices[:val_size_per_class])\n",
    "    train_indices.extend(indices[val_size_per_class:])\n",
    "\n",
    "train_dataset = Subset(full_train_dataset, train_indices)\n",
    "val_dataset   = Subset(full_val_dataset,   val_indices)\n",
    "\n",
    "print(f\"Final splits → Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "\n",
    "# ---------------- LOADERS ----------------\n",
    "train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "val_loader   = DataLoader(val_dataset,   BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "test_loader  = DataLoader(test_dataset,  BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "print(\"✓ Vision-only dataset ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Model Definition (backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ====================== FULL VISION-ONLY PIPELINE ======================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import timm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "NUM_CLASSES = 200\n",
    "VISION_DIM = 1024        # Swin-B output dim\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ====================== MODEL ======================\n",
    "class ViTMixSwin(nn.Module):\n",
    "    \"\"\"\n",
    "    Vision-only fine-grained classifier using Swin-B.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, freeze_vision=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # ---- Vision Encoder (Swin-B) ----\n",
    "        self.vision_encoder = timm.create_model(\n",
    "            \"swin_base_patch4_window7_224\",\n",
    "            pretrained=True,\n",
    "            num_classes=0,       # remove classifier\n",
    "            global_pool=\"avg\"    # output (B, 1024)\n",
    "        )\n",
    "\n",
    "        if freeze_vision:\n",
    "            for p in self.vision_encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        # ---- Classification Head ----\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(VISION_DIM, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(512, NUM_CLASSES),\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        v_feat = self.vision_encoder(images)\n",
    "        logits = self.classifier(v_feat)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "# ====================== USAGE EXAMPLE ======================\n",
    "# model = ViTMixSwin(freeze_vision=True).to(DEVICE)\n",
    "# optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=3e-4, weight_decay=1e-4)\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=20)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# history, best_state = train_model(model, train_loader, val_loader, optimizer, criterion, DEVICE,\n",
    "#                                   epochs=20, scheduler=scheduler, amp=True, unfreeze_after=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4 Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ====================== METRICS ======================\n",
    "@torch.no_grad()\n",
    "def accuracy(logits, targets, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batch_size = targets.size(0)\n",
    "    _, preds = logits.topk(maxk, dim=1, largest=True, sorted=True)\n",
    "    preds = preds.t()\n",
    "    correct = preds.eq(targets.view(1, -1).expand_as(preds))\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "class AverageMeter:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = self.sum = self.count = self.avg = 0.0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "# ====================== TRAIN / VALIDATION ======================\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, scaler=None):\n",
    "    model.train()\n",
    "    loss_meter = AverageMeter(\"train_loss\")\n",
    "    acc1_meter = AverageMeter(\"train_acc1\")\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Train\", leave=False, colour=\"green\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if scaler:\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        acc1 = accuracy(outputs, labels, topk=(1,))[0]\n",
    "        bs = images.size(0)\n",
    "        loss_meter.update(loss.item(), bs)\n",
    "        acc1_meter.update(acc1.item(), bs)\n",
    "\n",
    "    return {\"train_loss\": loss_meter.avg, \"train_acc1\": acc1_meter.avg}\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    loss_meter = AverageMeter(\"val_loss\")\n",
    "    acc1_meter = AverageMeter(\"val_acc1\")\n",
    "    acc5_meter = AverageMeter(\"val_acc5\")\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Validate\", leave=False, colour=\"red\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        acc1, acc5 = accuracy(outputs, labels, topk=(1,5))\n",
    "        bs = images.size(0)\n",
    "        loss_meter.update(loss.item(), bs)\n",
    "        acc1_meter.update(acc1.item(), bs)\n",
    "        acc5_meter.update(acc5.item(), bs)\n",
    "\n",
    "    return {\"val_loss\": loss_meter.avg, \"val_acc1\": acc1_meter.avg, \"val_acc5\": acc5_meter.avg}\n",
    "\n",
    "# ====================== FULL TRAINING LOOP ======================\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion,\n",
    "                device, epochs=20, scheduler=None, amp=True, unfreeze_after=5,\n",
    "                save_dir=\".\", best_model_name=\"best_model.pth\", log_csv_name=\"training_log.csv\"):\n",
    "    \"\"\"\n",
    "    Full training with explicit saving of all metrics per epoch in CSV,\n",
    "    and best model saved in PyTorch format.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    scaler = GradScaler() if amp else None\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "    history = []\n",
    "\n",
    "    # Initialize CSV file\n",
    "    log_path = os.path.join(save_dir, log_csv_name)\n",
    "    df_columns = [\"epoch\",\"train_loss\",\"train_acc1\",\"val_loss\",\"val_acc1\",\"val_acc5\"]\n",
    "    pd.DataFrame(columns=df_columns).to_csv(log_path, index=False)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # Partial unfreeze\n",
    "        if epoch == unfreeze_after:\n",
    "            print(\">> Unfreezing last 2 Swin blocks for fine-tuning...\")\n",
    "            for name, param in model.vision_encoder.named_parameters():\n",
    "                if \"layers.2\" in name or \"layers.3\" in name:\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        train_metrics = train_one_epoch(model, train_loader, optimizer, criterion, device, scaler)\n",
    "        val_metrics = validate_one_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        metrics = {\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_metrics[\"train_loss\"],\n",
    "            \"train_acc1\": train_metrics[\"train_acc1\"],\n",
    "            \"val_loss\": val_metrics[\"val_loss\"],\n",
    "            \"val_acc1\": val_metrics[\"val_acc1\"],\n",
    "            \"val_acc5\": val_metrics[\"val_acc5\"]\n",
    "        }\n",
    "        history.append(metrics)\n",
    "\n",
    "        # Append metrics to CSV\n",
    "        pd.DataFrame([metrics]).to_csv(log_path, mode='a', header=False, index=False)\n",
    "\n",
    "        # Save best model explicitly\n",
    "        if val_metrics[\"val_acc1\"] > best_val_acc:\n",
    "            best_val_acc = val_metrics[\"val_acc1\"]\n",
    "            best_state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"val_acc1\": best_val_acc\n",
    "            }\n",
    "            torch.save(best_state, os.path.join(save_dir, best_model_name))\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{epochs}] | \"\n",
    "              f\"Train Loss: {train_metrics['train_loss']:.4f}, Train Acc: {train_metrics['train_acc1']:.2f}% | \"\n",
    "              f\"Val Loss: {val_metrics['val_loss']:.4f}, Val Acc: {val_metrics['val_acc1']:.2f}%\")\n",
    "\n",
    "    return history, best_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STARTING TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = ViTMixSwin(freeze_vision=True).to(DEVICE)\n",
    "\n",
    "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=20)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "history, best_state = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE,\n",
    "    epochs=20,\n",
    "    scheduler=scheduler,\n",
    "    amp=True,\n",
    "    unfreeze_after=5\n",
    ")\n",
    "\n",
    "# -------------------- 4️⃣ Print best validation accuracy --------------------\n",
    "print(f\"\\n✓ Best validation accuracy: {best_state['val_acc1']:.2f}% at epoch {best_state['epoch']}\")\n",
    "test_metrics = validate_one_epoch(\n",
    "    model=model, \n",
    "    loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "print(\"\\n=== TEST RESULTS ===\")\n",
    "print(f\"Top-1 Accuracy: {test_metrics['val_acc1']:.2f}%\")\n",
    "print(f\"Top-5 Accuracy: {test_metrics['val_acc5']:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2534241,
     "sourceId": 5140550,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8137285,
     "sourceId": 13474668,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
